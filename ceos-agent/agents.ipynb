{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "https://python.langchain.com/docs/modules/agents/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.schema.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "debug=False\n",
    "set_verbose(debug)\n",
    "set_debug(debug)\n",
    "\n",
    "OpenAPIKey = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Tool Test\n",
    "\n",
    "This is excluding the runtime, hence it will resolve the function call and the arguments but not actually call the function (called tool in langchain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='get_word_length', tool_input={'word': 'cookie worm'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'cookie worm'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"word\": \"cookie worm\"\\n}', 'name': 'get_word_length'}})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "tools = [get_word_length]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = model.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent.invoke({\"input\": \"how many letters in the word cookie worm?\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Runtime\n",
    "\n",
    "This will drive the completion of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL NAME: get_word_length\n",
      "TOOL INPUT: {'word': 'cookie worm'}\n",
      "There are 11 letters in the word \"cookie worm\".\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "user_input = \"how many letters in the word cookie worm?\"\n",
    "intermediate_steps = []\n",
    "while True:\n",
    "    output = agent.invoke(\n",
    "        {\n",
    "            \"input\": user_input,\n",
    "            \"intermediate_steps\": intermediate_steps,\n",
    "        }\n",
    "    )\n",
    "    if isinstance(output, AgentFinish):\n",
    "        final_result = output.return_values[\"output\"]\n",
    "        break\n",
    "    else:\n",
    "        print(f\"TOOL NAME: {output.tool}\")\n",
    "        print(f\"TOOL INPUT: {output.tool_input}\")\n",
    "        tool = {\"get_word_length\": get_word_length}[output.tool]\n",
    "        observation = tool.run(output.tool_input)\n",
    "        intermediate_steps.append((output, observation))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Built-in Executor: AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'cookie worm'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m11\u001b[0m\u001b[32;1m\u001b[1;3mThere are 11 letters in the word \"cookie worm\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how many letters in the word cookie worm?',\n",
       " 'output': 'There are 11 letters in the word \"cookie worm\".'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=debug)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"how many letters in the word cookie worm?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Memory to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are very powerful assistant, but bad at calculating lengths of words.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=debug)\n",
    "\n",
    "# First call\n",
    "input = \"how many letters in the word cookie worm?\"\n",
    "result = agent_executor.invoke({\"input\": input, \"chat_history\": chat_history})\n",
    "\n",
    "# Add messages to chat history\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Second call\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all Built-in Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import get_all_tool_names\n",
    "get_all_tool_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My First Custom Tool (SMHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving weather forecast for lat: 59.3293, lon: 18.0686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'temperature': -0.8, 'wind_speed': 6.6, 'precipitation': 0.1}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Type\n",
    "\n",
    "\n",
    "class ForecastInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location\")\n",
    "\n",
    "class ForecastOutput(BaseModel):\n",
    "    temperature: Optional[float] = Field(None, description=\"Temperature in degrees Celsius\")\n",
    "    wind_speed: Optional[float] = Field(None, description=\"Wind speed in meters per second\")\n",
    "    precipitation: Optional[float] = Field(None, description=\"Precipitation in millimeters\")\n",
    "\n",
    "class ForecastTool(StructuredTool):\n",
    "    args_schema: Type[BaseModel] = ForecastInput\n",
    "    return_schema: Type[BaseModel] = ForecastOutput\n",
    "    name: str = \"forecast\"\n",
    "    description: str = \"Useful when you need to answer a question about weather in a specific location.\"\n",
    "\n",
    "    def _run(self, input: ForecastInput) -> ForecastOutput:\n",
    "        # SMHI API endpoint for weather forecast\n",
    "        url = f\"https://opendata-download-metfcst.smhi.se/api/category/pmp3g/version/2/geotype/point/lon/{input.longitude}/lat/{input.latitude}/data.json\"\n",
    "\n",
    "        print(f\"Retrieving weather forecast for lat: {input.latitude}, lon: {input.longitude}\")\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return self.extract_weather_info(response=response)\n",
    "        else:\n",
    "            raise Exception(\"Error: Could not retrieve the weather forecast.\")\n",
    "\n",
    "    def extract_weather_info(self, response: requests.Response) -> ForecastOutput:\n",
    "        forecast=response.json()\n",
    "        \n",
    "        if 'timeSeries' in forecast and len(forecast['timeSeries']) > 0:\n",
    "            # The first element in the time series is usually the current weather forecast\n",
    "            current_forecast = forecast['timeSeries'][0]\n",
    "\n",
    "            weather_info: ForecastOutput = {\n",
    "                'temperature': None,\n",
    "                'wind_speed': None,\n",
    "                'precipitation': None\n",
    "            }\n",
    "\n",
    "            for parameter in current_forecast['parameters']:\n",
    "                if parameter['name'] == 't':  # Temperature\n",
    "                    weather_info['temperature'] = parameter['values'][0]\n",
    "                elif parameter['name'] == 'ws':  # Wind speed\n",
    "                    weather_info['wind_speed'] = parameter['values'][0]\n",
    "                elif parameter['name'] == 'pmean':  # Mean precipitation\n",
    "                    weather_info['precipitation'] = parameter['values'][0]\n",
    "\n",
    "            return weather_info\n",
    "        else:\n",
    "            raise Exception(\"Error: Could not parse the weather forecast.\")\n",
    "\n",
    "\n",
    "# Replace with the coordinates of your city in Sweden\n",
    "latitude = \"59.3293\"  # Example: Stockholm\n",
    "longitude = \"18.0686\"\n",
    "\n",
    "forecast_tool = ForecastTool()\n",
    "forecast_tool._run(ForecastInput(latitude=latitude, longitude=longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SMHI Tool in Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo get the current weather information for Skellefteå, I can use a weather API. However, as a text-based AI, I don't have direct access to real-time data. I suggest you check a reliable weather website or use a weather app on your device to get the most accurate and up-to-date information about the temperature in Skellefteå.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'how cold is it in Skellefteå?', 'output': \"To get the current weather information for Skellefteå, I can use a weather API. However, as a text-based AI, I don't have direct access to real-time data. I suggest you check a reliable weather website or use a weather app on your device to get the most accurate and up-to-date information about the temperature in Skellefteå.\"}\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are very powerful assistant, but you need to use a tool get weather info.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[ForecastTool()], verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({\"input\": \"how cold is it in Skellefteå?\"})\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
