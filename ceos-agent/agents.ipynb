{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "https://python.langchain.com/docs/modules/agents/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.schema.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "debug=False\n",
    "set_verbose(debug)\n",
    "set_debug(debug)\n",
    "\n",
    "OpenAPIKey = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Tool Test\n",
    "\n",
    "This is excluding the runtime, hence it will resolve the function call and the arguments but not actually call the function (called tool in langchain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='get_word_length', tool_input={'word': 'cookie worm'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'cookie worm'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"word\": \"cookie worm\"\\n}', 'name': 'get_word_length'}})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "tools = [get_word_length]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = model.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent.invoke({\"input\": \"how many letters in the word cookie worm?\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Runtime\n",
    "\n",
    "This will drive the completion of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL NAME: get_word_length\n",
      "TOOL INPUT: {'word': 'cookie worm'}\n",
      "There are 11 letters in the word \"cookie worm\".\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "user_input = \"how many letters in the word cookie worm?\"\n",
    "intermediate_steps = []\n",
    "myTools = {\"get_word_length\": get_word_length}\n",
    "\n",
    "while True:\n",
    "    output = agent.invoke(\n",
    "        {\n",
    "            \"input\": user_input,\n",
    "            \"intermediate_steps\": intermediate_steps,\n",
    "        }\n",
    "    )\n",
    "    if isinstance(output, AgentFinish):\n",
    "        final_result = output.return_values[\"output\"]\n",
    "        break\n",
    "    else:\n",
    "        print(f\"TOOL NAME: {output.tool}\")\n",
    "        print(f\"TOOL INPUT: {output.tool_input}\")\n",
    "        tool = myTools[output.tool]\n",
    "        observation = tool.run(output.tool_input)\n",
    "        intermediate_steps.append((output, observation))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Built-in Executor: AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'how many letters in the word cookie worm?',\n",
       " 'output': 'There are 11 letters in the word \"cookie worm\".'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = AgentExecutor(agent=agent, tools=tools, verbose=debug)\n",
    "\n",
    "chain.invoke({\"input\": \"how many letters in the word cookie worm?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Memory to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word cookie worm?'),\n",
       "  AIMessage(content='There are 11 letters in the word \"cookie worm\".')],\n",
       " 'output': '\"Cookie worm\" is not a real word. It is a combination of two separate words, \"cookie\" and \"worm\".'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are very powerful assistant, but bad at calculating lengths of words.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "chain = AgentExecutor(agent=agent, tools=tools, verbose=debug)\n",
    "\n",
    "# First call\n",
    "input = \"how many letters in the word cookie worm?\"\n",
    "result = chain.invoke({\"input\": input, \"chat_history\": chat_history})\n",
    "\n",
    "# Add messages to chat history\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Second call\n",
    "chain.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all Built-in Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python_repl',\n",
       " 'requests',\n",
       " 'requests_get',\n",
       " 'requests_post',\n",
       " 'requests_patch',\n",
       " 'requests_put',\n",
       " 'requests_delete',\n",
       " 'terminal',\n",
       " 'sleep',\n",
       " 'wolfram-alpha',\n",
       " 'google-search',\n",
       " 'google-search-results-json',\n",
       " 'searx-search-results-json',\n",
       " 'bing-search',\n",
       " 'metaphor-search',\n",
       " 'ddg-search',\n",
       " 'google-serper',\n",
       " 'google-scholar',\n",
       " 'google-serper-results-json',\n",
       " 'searchapi',\n",
       " 'searchapi-results-json',\n",
       " 'serpapi',\n",
       " 'dalle-image-generator',\n",
       " 'twilio',\n",
       " 'searx-search',\n",
       " 'wikipedia',\n",
       " 'arxiv',\n",
       " 'golden-query',\n",
       " 'pubmed',\n",
       " 'human',\n",
       " 'awslambda',\n",
       " 'sceneXplain',\n",
       " 'graphql',\n",
       " 'openweathermap-api',\n",
       " 'dataforseo-api-search',\n",
       " 'dataforseo-api-search-json',\n",
       " 'eleven_labs_text2speech',\n",
       " 'google_cloud_texttospeech',\n",
       " 'news-api',\n",
       " 'tmdb-api',\n",
       " 'podcast-api',\n",
       " 'memorize',\n",
       " 'llm-math',\n",
       " 'open-meteo-api']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import get_all_tool_names\n",
    "get_all_tool_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My First Custom Tool (SMHI)\n",
    "\n",
    "https://blog.langchain.dev/structured-tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sync) Retrieving weather forecast for lat: 64.7514, lon: 20.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'temperature': -12.9, 'wind_speed': 5.2, 'precipitation': 0.1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import aiohttp\n",
    "from requests.exceptions import HTTPError\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Type\n",
    "\n",
    "\n",
    "class ForecastInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location\")\n",
    "\n",
    "class ForecastOutput(BaseModel):\n",
    "    temperature: Optional[float] = Field(None, description=\"Temperature in degrees Celsius\")\n",
    "    wind_speed: Optional[float] = Field(None, description=\"Wind speed in meters per second\")\n",
    "    precipitation: Optional[float] = Field(None, description=\"Precipitation in millimeters\")\n",
    "\n",
    "class ForecastTool(StructuredTool):\n",
    "    name: str = \"GetWeatherForecast\"\n",
    "    description: str = \"Useful when you need to answer a question about weather in a specific location.\"\n",
    "    args_schema: Type[BaseModel] = ForecastInput\n",
    "        # SMHI API endpoint for weather forecast\n",
    "    smhi_url = \"https://opendata-download-metfcst.smhi.se/api/category/pmp3g/version/2/geotype/point/lon/{input.longitude}/lat/{input.latitude}/data.json\"\n",
    "\n",
    "\n",
    "    def _run(self, latitude: float, longitude: float) -> ForecastOutput:\n",
    "        print(f\"(sync) Retrieving weather forecast for lat: {latitude}, lon: {longitude}\")\n",
    "\n",
    "        url = self.smhi_url.format(input=ForecastInput(latitude=latitude, longitude=longitude))\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return self.extract_weather_info(response=response)\n",
    "        else:\n",
    "            raise HTTPError(f'Unexpected status code: {response.status_code}')\n",
    "        \n",
    "    async def _arun(self, latitude: float, longitude: float) -> ForecastOutput:\n",
    "        print(f\"(async) Retrieving weather forecast for lat: {latitude}, lon: {longitude}\")\n",
    "\n",
    "        url = self.smhi_url.format(input=ForecastInput(latitude=latitude, longitude=longitude))\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    return self.extract_weather_info(response=response)\n",
    "                else:\n",
    "                    raise HTTPError(f'Unexpected status code: {response.status_code}')\n",
    "\n",
    "    def extract_weather_info(self, response: requests.Response) -> ForecastOutput:\n",
    "        forecast=response.json()\n",
    "        \n",
    "        if 'timeSeries' in forecast and len(forecast['timeSeries']) > 0:\n",
    "            # The first element in the time series is usually the current weather forecast\n",
    "            current_forecast = forecast['timeSeries'][0]\n",
    "\n",
    "            weather_info: ForecastOutput = {\n",
    "                'temperature': None,\n",
    "                'wind_speed': None,\n",
    "                'precipitation': None\n",
    "            }\n",
    "\n",
    "            for parameter in current_forecast['parameters']:\n",
    "                if parameter['name'] == 't':  # Temperature\n",
    "                    weather_info['temperature'] = parameter['values'][0]\n",
    "                elif parameter['name'] == 'ws':  # Wind speed\n",
    "                    weather_info['wind_speed'] = parameter['values'][0]\n",
    "                elif parameter['name'] == 'pmean':  # Mean precipitation\n",
    "                    weather_info['precipitation'] = parameter['values'][0]\n",
    "\n",
    "            return weather_info\n",
    "        else:\n",
    "            raise KeyError(\"Error: Could not parse the weather forecast.\")\n",
    "\n",
    "\n",
    "# Replace with the coordinates of your city in Sweden\n",
    "latitude = \"64.7514\"  # Example: Skellefteå\n",
    "longitude = \"20.9579\"\n",
    "\n",
    "forecast_tool = ForecastTool()\n",
    "forecast_tool._run(latitude, longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SMHI Tool in Agent\n",
    "\n",
    "https://nanonets.com/blog/langchain/\n",
    "\n",
    "https://api.python.langchain.com/en/latest/experimental_api_reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sync) Retrieving weather forecast for lat: 64.75, lon: 20.95\n",
      "{'input': 'how cold is it in Skellefteå?', 'agent_scratchpad': [], 'output': 'The current temperature in Skellefteå is -12.9 degrees Celsius.'}\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are very powerful assistant, but you need to use a tool get weather info.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"Observation\"]) # Stops on Observation\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "chain = initialize_agent(\n",
    "  agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "  llm=model,\n",
    "  tools=[ForecastTool()], verbose=debug\n",
    ")\n",
    "\n",
    "result = chain.invoke({\n",
    "  \"input\": \"how cold is it in Skellefteå?\",\n",
    "  \"agent_scratchpad\": [],\n",
    "  })\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
